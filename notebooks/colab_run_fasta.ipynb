{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3fba5d8",
      "metadata": {
        "id": "a3fba5d8"
      },
      "source": [
        "# NARDINI Online Fasta Analysis\n",
        "\n",
        "This tool, developed by Cohan et al., conducts statistical analysis of **amino acid patterning** within intrisically disordered regions (**IDRs**).\n",
        "\n",
        "The inputs and outputs are the same as command-line NARDINI. The input is a **.fasta** file of IDRs; the output is a **.zip** containing **.tsv** and **.png** files.\n",
        "\n",
        "This notebook sends the FASTA to be processed to an external server, where NARDINI statistical analysis is performed. **You can close this notebook and the analysis will still run, and then come back and get your results.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16d7363b",
      "metadata": {
        "id": "16d7363b"
      },
      "source": [
        "# Usage Instructions\n",
        "\n",
        "1. **Setup** - Install dependencies\n",
        "2. **Test Connection** - Verify service is available\n",
        "3. **Select FASTA** - Choose your input file\n",
        "4. **Run Analysis** - Submit file for processing (get Run ID)\n",
        "5. **Check Progress** - Monitor analysis status\n",
        "6. **Download Results** - Get your results when complete\n",
        "\n",
        "## Output\n",
        "Results will be saved to `data/zip_outputs/` folder containing:\n",
        "- A zip file with your analysis results\n",
        "- Run information text files for reference\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Installations\n",
        "#@markdown First, set up the dependencies needed to run NARDINI.\n",
        "%%capture\n",
        "import os\n",
        "import datetime\n",
        "import json\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional\n",
        "from typing_extensions import Literal, TypedDict\n",
        "from google.colab import files\n",
        "\n",
        "## Defining schemas for the data to be recived from the server ##\n",
        "\n",
        "# ---- Public API response schemas ----\n",
        "class ErrorResponse(TypedDict):\n",
        "    error: str\n",
        "\n",
        "class HealthResponse(TypedDict):\n",
        "    status: Literal[\"healthy\"]\n",
        "\n",
        "class UploadFastaResponse(TypedDict):\n",
        "    run_id: str\n",
        "    status: Literal[\"submitted\", \"ready\"]\n",
        "    message: str\n",
        "    job_ids: List[str]\n",
        "\n",
        "class StatusResponse(TypedDict):\n",
        "    run_id: str\n",
        "    status: Literal[\"pending\", \"complete\"]\n",
        "    pending_sequences: List[str]\n",
        "\n",
        "class RetryResponse(TypedDict):\n",
        "    run_id: str\n",
        "    status: Literal[\"retry_submitted\"]\n",
        "\n",
        "class SimplifiedDownloadResponse(TypedDict):\n",
        "    run_id: str\n",
        "    destination_filepath: str\n",
        "\n",
        "# ---- Backend metadata schemas (stored in volume as JSON) ----\n",
        "\n",
        "class SequenceInput(TypedDict):\n",
        "    sequence: Any  # Bio.SeqRecord object\n",
        "    seq_uuid: str\n",
        "\n",
        "class SequenceData(TypedDict):\n",
        "    sequence_id: str\n",
        "    status: Literal[\"pending\", \"cached\", \"pending_external\", \"complete\"]\n",
        "    start_time: Optional[float]\n",
        "    end_time: Optional[float]\n",
        "    seq_uuid: Optional[str]\n",
        "    zip_path: Optional[str]\n",
        "    job_id: Optional[str]\n",
        "\n",
        "SequenceString = str\n",
        "SequencesMapping = Dict[SequenceString, SequenceData]\n",
        "\n",
        "class RunData(TypedDict):\n",
        "    status: Literal[\"pending\", \"complete\"]\n",
        "    fasta_filename: str\n",
        "    output_filename: str\n",
        "    sequences: SequencesMapping\n",
        "    total_sequences: int\n",
        "    cached_sequences: int\n",
        "    merged_zip_filename: Optional[str]\n",
        "    submitted_at: float\n",
        "    completed_at: Optional[float]\n",
        "\n",
        "## Set up functions to be used in the notebook ##\n",
        "def test_health(url: str):\n",
        "    \"\"\"Test if the NARDINI backend service is healthy.\"\"\"\n",
        "    try:\n",
        "        health_response = requests.get(f\"{url}/health\")\n",
        "        if health_response.ok:\n",
        "            res = health_response.json()\n",
        "            return HealthResponse(status=res[\"status\"])\n",
        "        else:\n",
        "            return ErrorResponse(\n",
        "                error=f\"Error: {health_response.status_code} {health_response.text}\"\n",
        "            )\n",
        "    except Exception as e:\n",
        "        return ErrorResponse(error=f\"Connection error: {e}\")\n",
        "\n",
        "# Main function to run Nardini\n",
        "def upload_fasta(\n",
        "    url: str, fasta_filepath: Path | str\n",
        ") -> UploadFastaResponse | ErrorResponse:\n",
        "    \"\"\"Submit a FASTA file for NARDINI analysis.\"\"\"\n",
        "    if not Path(fasta_filepath).exists():\n",
        "        raise FileNotFoundError(f\"File {fasta_filepath} does not exist\")\n",
        "\n",
        "    with open(fasta_filepath, \"rb\") as f:\n",
        "        files = {\"file\": f}\n",
        "        response = requests.post(f\"{url}/upload_fasta\", files=files)\n",
        "    if response.ok:\n",
        "        res = response.json()\n",
        "        return UploadFastaResponse(\n",
        "            run_id=res[\"run_id\"],\n",
        "            status=res[\"status\"],\n",
        "            message=res[\"message\"],\n",
        "            job_ids=res[\"job_ids\"],\n",
        "        )\n",
        "    else:\n",
        "        return ErrorResponse(error=f\"Error: {response.status_code} {response.text}\")\n",
        "\n",
        "def get_run_status(url: str, run_id: str):\n",
        "    \"\"\"Check the status of a NARDINI analysis run.\"\"\"\n",
        "    try:\n",
        "        status_response = requests.get(f\"{url}/status/{run_id}\")\n",
        "        if status_response.ok:\n",
        "            res = status_response.json()\n",
        "            return StatusResponse(\n",
        "                run_id=res[\"run_id\"],\n",
        "                status=res[\"status\"],\n",
        "                pending_sequences=res[\"pending_sequences\"],\n",
        "            )\n",
        "        else:\n",
        "            return f\"Error: {status_response.status_code} {status_response.text}\"\n",
        "    except Exception as e:\n",
        "        return f\"Connection error: {e}\"\n",
        "\n",
        "def download_zip(\n",
        "    url: str, run_id: str, destination_dir: Path | str = '/content/nardini_results'\n",
        ") -> SimplifiedDownloadResponse | ErrorResponse:\n",
        "    \"\"\"Download the results zip file for a completed analysis.\"\"\"\n",
        "    if not run_id:\n",
        "        return ErrorResponse(error=\"Please provide a valid Run ID.\")\n",
        "\n",
        "    destination_dir = Path(destination_dir)\n",
        "    if not destination_dir.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Destination directory {destination_dir} does not exist\"\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        response = requests.get(\n",
        "            f\"{url}/download/{run_id}\", stream=True\n",
        "        )\n",
        "        if response.ok:\n",
        "            # Extract filename from response headers\n",
        "            content_disposition = response.headers.get(\"content-disposition\", \"\")\n",
        "            if \"filename=\" in content_disposition:\n",
        "                filename = content_disposition.split(\"filename=\")[1].strip('\"')\n",
        "                destination_filepath = destination_dir / filename\n",
        "            else:\n",
        "                destination_filepath = destination_dir / f\"{run_id}.zip\"\n",
        "\n",
        "            with open(destination_filepath, \"wb\") as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "            # print(f\"Downloaded results to: {destination_filepath}\")\n",
        "            # print(\n",
        "            #     f\"File size: {destination_filepath.stat().st_size / (1024 * 1024):.1f} MB\"\n",
        "            # )\n",
        "            return SimplifiedDownloadResponse(\n",
        "                run_id=run_id, destination_filepath=str(destination_filepath)\n",
        "            )\n",
        "        else:\n",
        "            print(\"Analysis is likely still in progress!\")\n",
        "            return ErrorResponse(\n",
        "                error=f\"Error downloading file: {response.status_code} {response.text}\"\n",
        "            )\n",
        "    except Exception as e:\n",
        "        return ErrorResponse(error=f\"Download error: {e}\")\n",
        "\n",
        "def retry_sequences(url: str, run_id: str):\n",
        "    \"\"\"Retry processing for sequences that are still pending.\"\"\"\n",
        "    if not run_id:\n",
        "        return ErrorResponse(error=\"Please provide a valid Run ID.\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(f\"{url}/retry/{run_id}\")\n",
        "        if response.ok:\n",
        "            res = response.json()\n",
        "            return RetryResponse(run_id=res[\"run_id\"], status=res[\"status\"])\n",
        "        else:\n",
        "            return ErrorResponse(\n",
        "                error=f\"Error retrying sequences: {response.status_code} {response.text}\"\n",
        "            )\n",
        "    except Exception as e:\n",
        "        return ErrorResponse(error=f\"Retry error: {e}\")\n",
        "\n",
        "def get_available_runs(output_dir: Path | str = '/content/nardini_results'):\n",
        "    \"\"\"Get all available runs from the JSON file.\"\"\"\n",
        "    json_path = Path(output_dir) / 'run_info.json' # Ensure json_path is a Path object\n",
        "    if not json_path.exists():\n",
        "        return []\n",
        "    try:\n",
        "        with open(json_path, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    except (json.JSONDecodeError, FileNotFoundError) as e:\n",
        "        print(f\"Error reading run info JSON: {e}\")\n",
        "        return []\n",
        "\n",
        "def save_run_info(run_id: str, fasta_filename: str, output_dir: Path | str = '/content/nardini_results'):\n",
        "    \"\"\"Save run information to a JSON file for reference.\"\"\"\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    output_dir = Path(output_dir)\n",
        "    json_path = output_dir / 'run_info.json'\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    if not output_dir.exists():\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "    run_info = {\n",
        "        \"title\": \"NARDINI Analysis Run Information\",\n",
        "        \"timestamp\": timestamp,\n",
        "        \"fasta_file\": fasta_filename,\n",
        "        \"run_id\": run_id\n",
        "    }\n",
        "\n",
        "    # Append to existing JSON or create new one\n",
        "    all_runs = get_available_runs(output_dir)\n",
        "    # Check if the run_id already exists, update if it does, otherwise append\n",
        "    found = False\n",
        "    for run in all_runs:\n",
        "        if run.get(\"run_id\") == run_id:\n",
        "            run.update(run_info)\n",
        "            found = True\n",
        "            break\n",
        "    if not found:\n",
        "        all_runs.append(run_info)\n",
        "\n",
        "\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(all_runs, f, indent=2)\n",
        "\n",
        "    return str(json_path)"
      ],
      "metadata": {
        "id": "fejVJWijSVDy",
        "cellView": "form"
      },
      "id": "fejVJWijSVDy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ee798a",
      "metadata": {
        "id": "c0ee798a",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Test connection to server\n",
        "BACKEND_URL = \"https://tangentleman--nardini-online-fastapi-app.modal.run\"\n",
        "print(\"Testing connection to NARDINI backend...\")\n",
        "test_result = test_health(BACKEND_URL)\n",
        "\n",
        "if test_result.get(\"error\"):\n",
        "    print(\"❌ Connection failed!\")\n",
        "    print(f\"Response: {test_result}\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"1. Check your internet connection\")\n",
        "    print(\"2. Verify the backend URL is correct\")\n",
        "    print(\"3. The server may be temporarily unavailable\")\n",
        "else:\n",
        "    print(\"✅ Connection to server established!\")\n",
        "    # print(f\"Backend URL: {BACKEND_URL}\")\n",
        "    # print(f\"Response: {test_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10f0578",
      "metadata": {
        "id": "b10f0578",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Select FASTA File 📁\n",
        "\n",
        "print(\"Please upload your FASTA file(s) using the widget below:\")\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    # Assuming a single FASTA file is uploaded\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    content = uploaded[filename]\n",
        "\n",
        "    # Write the content to a new file in the /content/ directory\n",
        "    FASTA_FILEPATH = f\"/content/{filename}\"\n",
        "    with open(FASTA_FILEPATH, 'wb') as f:\n",
        "        f.write(content)\n",
        "    print(f\"✅ Success!\")\n",
        "    # print(f\"\\n✅ File '{filename}' uploaded and saved to {FASTA_FILEPATH}\")\n",
        "    # print(f\"Set FASTA_FILEPATH to: {FASTA_FILEPATH}\")\n",
        "\n",
        "else:\n",
        "    print(\"⚠️ No files were uploaded.\")\n",
        "    FASTA_FILEPATH = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Optional: See prior runs\n",
        "runs = get_available_runs()\n",
        "#req_runs = runs(colname== 'run_id' & 'value')\n",
        "for item in runs:\n",
        "  print(f\"Run ID for {item.get('fasta_file')} : {item.get('run_id')}\")"
      ],
      "metadata": {
        "id": "lP2N8Pl2d6is",
        "cellView": "form"
      },
      "id": "lP2N8Pl2d6is",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f52679d2",
      "metadata": {
        "id": "f52679d2",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Submit file for analysis\n",
        "if FASTA_FILEPATH and Path(FASTA_FILEPATH).exists():\n",
        "    print(f\"\\n🔬 Submitting {Path(FASTA_FILEPATH).name} for NARDINI analysis...\")\n",
        "\n",
        "    try:\n",
        "        result = upload_fasta(BACKEND_URL, FASTA_FILEPATH)\n",
        "        if isinstance(result, dict) and \"run_id\" in result:\n",
        "            run_id = result[\"run_id\"]\n",
        "            print(\"✅ Analysis started successfully!\")\n",
        "\n",
        "            # Save run information to the specified OUTPUT_DIR\n",
        "            save_run_info(run_id, FASTA_FILEPATH)\n",
        "\n",
        "            print(\"\\n📝 Next steps:\")\n",
        "            print(\"1. Use the 'Check Progress' cell to monitor analysis\")\n",
        "            print(\"2. Use the 'Download Results' cell when complete\")\n",
        "        else:\n",
        "            print(f\"❌ Error submitting file: {result}\")\n",
        "            run_id = None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error occurred: {e}\")\n",
        "        run_id = None\n",
        "elif FASTA_FILEPATH:\n",
        "    print(f\"❌ File not found: {FASTA_FILEPATH}\")\n",
        "    run_id = None\n",
        "else:\n",
        "    print(\"⚠️  Please set FASTA_FILEPATH to the path of your FASTA file first!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f4a1041",
      "metadata": {
        "id": "1f4a1041",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Check Progress 🔍\n",
        "# Monitor the status of your NARDINI analysis\n",
        "# You can either use the run_id from the previous cell or enter one manually\n",
        "check_run_id = run_id\n",
        "\n",
        "# Option: Manually enter a run ID if needed (uncomment and modify)\n",
        "# check_run_id = \"your-run-id-here\"\n",
        "\n",
        "if not check_run_id:\n",
        "    print(\"⚠️  No Run ID available!\")\n",
        "    print(\"Either run the analysis cell above first, or manually set check_run_id\")\n",
        "else:\n",
        "    try:\n",
        "        status_dict = get_run_status(BACKEND_URL, check_run_id)\n",
        "\n",
        "        if isinstance(status_dict, dict):\n",
        "            status = status_dict.get(\"status\", \"unknown\")\n",
        "\n",
        "            if status == \"pending\":\n",
        "                print(\"⏳ Analysis is running...\")\n",
        "\n",
        "                # Show pending sequences\n",
        "                pending_sequences = status_dict.get(\"pending_sequences\", [])\n",
        "                if pending_sequences:\n",
        "                    remaining_count = len(pending_sequences)\n",
        "                    print(\"\\n📈 Progress Details:\")\n",
        "                    print(f\"⏱️  {remaining_count} sequences remaining to process\")\n",
        "\n",
        "                    # Show first few pending sequences (limit output)\n",
        "                    display_limit = min(5, len(pending_sequences))\n",
        "                    for i, sequence in enumerate(pending_sequences[:display_limit], 1):\n",
        "                        # Show only first 30 chars of sequence to keep output manageable\n",
        "                        short_seq = (\n",
        "                            sequence[:30] + \"...\" if len(sequence) > 30 else sequence\n",
        "                        )\n",
        "                        print(f\"  ⏳ {i}. {short_seq}\")\n",
        "\n",
        "                    if len(pending_sequences) > display_limit:\n",
        "                        print(\n",
        "                            f\"  ... and {len(pending_sequences) - display_limit} more sequences\"\n",
        "                        )\n",
        "                else:\n",
        "                    print(\"🔄 Processing has started, checking sequence completion...\")\n",
        "\n",
        "            elif status == \"complete\":\n",
        "                print(\"🎉 Analysis completed successfully!\")\n",
        "                print(\"📥 You can now download the results using the next cell.\")\n",
        "\n",
        "            else:\n",
        "                print(f\"ℹ️  Status: {status}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"❌ Error checking status: {status_dict}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error occurred while checking status: {e}\")\n",
        "\n",
        "print(\"\\n💡 Tip: Re-run this cell to get updated progress information\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69543ac0",
      "metadata": {
        "id": "69543ac0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Download Results 📥\n",
        "# Download the completed NARDINI analysis results\n",
        "\n",
        "# Use the run_id from previous cells or enter one manually\n",
        "download_run_id = run_id\n",
        "\n",
        "# Option: Manually enter a run ID if needed (uncomment and modify)\n",
        "# download_run_id = \"your-run-id-here\"\n",
        "\n",
        "if not download_run_id:\n",
        "    print(\"⚠️  No Run ID available!\")\n",
        "    print(\"Upload a file and try again!\")\n",
        "else:\n",
        "    # print(f\"\\n📥 Downloading results for: {download_run_id}\")\n",
        "\n",
        "    # Attempt download directly\n",
        "    try:\n",
        "        results = download_zip(BACKEND_URL, download_run_id)\n",
        "        if results.get(\"error\"):\n",
        "            print(f\"❌ Download failed: {results.get('error')}\")\n",
        "            print(\"The analysis may still be in progress or an error occurred\")\n",
        "            print(\"Use the 'Check Progress' cell to verify the analysis status\")\n",
        "        else:\n",
        "            print(\"\\n🎉 Download successful!\")\n",
        "            print(\"Click the folder icon on the leftmost taskbar of this notebook to view 'nardini_results'!\")\n",
        "            print(f\"📁 Results saved to: {results.get('destination_filepath')}\")\n",
        "            download_link = f\"{BACKEND_URL}/download/{download_run_id}\"\n",
        "            print(f\"You can also download your file at this link:\\n{download_link}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error occurred during download: {e}\")\n",
        "        print(\"The analysis may still be in progress or there was a connection issue\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73f29822",
      "metadata": {
        "id": "73f29822"
      },
      "source": [
        "# Credits\n",
        "\n",
        "**✨ Made by Tanuj Vasudeva and Ethan Caine, 2025 ✨**\n",
        "\n",
        "This notebook has been adapted for use in any Jupyter environment, not just Google Colab.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15350a48",
      "metadata": {
        "id": "15350a48"
      },
      "source": [
        "# Acknowledgments\n",
        "\n",
        "We would like to thank Dr. John Woolford at Carnegie Mellon University — for whose lab this notebook was made — for his support of this project; Modal for hosting this service; Katherine Parry for helpful advice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68e6340d",
      "metadata": {
        "id": "68e6340d"
      },
      "source": [
        "\n",
        "# References\n",
        "\n",
        "Cohan, M. C., Shinn, M. K., Lalmansingh, J. M., & Pappu, R. V. (2021). Uncovering non-random binary patterns within sequences of intrinsically disordered proteins. *Journal of Molecular Biology*, 434(2), 167373.\n",
        "\n",
        "## Additional Information\n",
        "\n",
        "- **NARDINI Tool**: This notebook provides a user-friendly interface to the NARDINI analysis tool\n",
        "- **Backend Service**: Analysis is performed on remote servers for optimal performance\n",
        "- **Output Format**: Results include statistical data (.tsv files) and visualization plots (.png files)\n",
        "- **Caching**: Previously analyzed sequences are cached to speed up repeat analyses"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}